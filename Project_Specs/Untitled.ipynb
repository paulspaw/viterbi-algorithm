{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "# from __future__ import division\n",
    "\n",
    "def read_state(State_File):\n",
    "    '''\n",
    "    :param State_File: file includes state set and state transition matrix\n",
    "    :return N: number of states\n",
    "    :return state_set: a dict contains all states' ID and name\n",
    "    :return transition_prob: a dict contains transition probability \n",
    "    :return state_prob: a dict contains states and their probability\n",
    "    '''\n",
    "    with open(State_File, 'r') as file:\n",
    "        N = int(file.readline().strip('\\n'))     # read the first line to get N value\n",
    "        state_set = dict()                       # store the set of state\n",
    "        transition_prob = dict()                 # store transition probability  \n",
    "        state_prob = dict()                      # store state initialising probability\n",
    "        ID = 0                                   # ID of states\n",
    "        cnt = 0                                  # number of transitions\n",
    "        \n",
    "        # Scan descriptive name of the states.\n",
    "        while ID < N:\n",
    "            state = file.readline().strip('\\n').rstrip()  # one state in each line\n",
    "            state_set[state] = ID\n",
    "            ID = ID + 1\n",
    "        \n",
    "        # Scan the frequency of transitions.\n",
    "        while True:\n",
    "            line = file.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            items = line.split(' ')\n",
    "            # Add new probability with key + value.\n",
    "            transition_prob.setdefault(int(items[0]),{})[int(items[1])] = int(items[2])\n",
    "            cnt = cnt + 1\n",
    "        \n",
    "        # Convert frequency into probability.\n",
    "        for keys,values in transition_prob.items():\n",
    "            total = 0\n",
    "            for value in values.values():\n",
    "                total = total + value\n",
    "            # Scan each state in state_set.\n",
    "            for state in state_set.values():\n",
    "                # Case-I: state is already existing\n",
    "                if state in values.keys():\n",
    "#                     transition_prob[keys][state] = round((transition_prob[keys][state]+1)/(total+N-1),1)\n",
    "                    transition_prob[keys][state] = (transition_prob[keys][state]+1)/(total+N-1)\n",
    "                # Case-II: state is not existing\n",
    "                else:\n",
    "                    if state == state_set['BEGIN']:\n",
    "                        transition_prob.setdefault(keys,{})[state] = 0.0\n",
    "                    else:\n",
    "#                         transition_prob.setdefault(keys,{})[state] = round(1/(total+N-1),1)\n",
    "                        transition_prob.setdefault(keys,{})[state] = 1/(total+N-1)\n",
    "            \n",
    "        # Initialize state probability and Add \"END\" state with no outing states.\n",
    "        for state in state_set.values():\n",
    "            transition_prob.setdefault(state_set['END'],{})[state] = 0.0\n",
    "#             state_prob[state] = round(1/N,1)\n",
    "            state_prob[state] = 1/N\n",
    "            \n",
    "    return N, state_set, transition_prob, state_prob\n",
    "\n",
    "def read_symbol(Symbol_File, state_set):\n",
    "    '''\n",
    "    :param Symbol_File: file includes symbol set and emission probability\n",
    "    :param state_set: a set of state\n",
    "    :return M: number of symbol\n",
    "    :return symbol_set: a dict contains all symbols' ID and name\n",
    "    :return emission_prob: a dict contains emission probability \n",
    "    '''\n",
    "    with open(Symbol_File, 'r') as file:\n",
    "        M = int(file.readline().strip('\\n'))     # read the first line to get M value\n",
    "        symbol_set = dict()                      # store the set of symbol\n",
    "        emission_prob = dict()                   # store emission probability        \n",
    "        ID = 0                                   # ID of symbols\n",
    "        \n",
    "        # Scan descriptive name of the symbols.\n",
    "        while ID < M:\n",
    "            symbol = file.readline().strip('\\n').rstrip()  # one symbol in each line\n",
    "#             symbol_set[ID] = symbol\n",
    "            symbol_set[symbol] = ID\n",
    "            ID = ID + 1\n",
    "        \n",
    "        # Scan the frequency of emissions.\n",
    "        while True:\n",
    "            line = file.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            items = line.split(' ')\n",
    "            # Add new probability with key + value.\n",
    "            emission_prob.setdefault(int(items[0]),{})[int(items[1])] = int(items[2])\n",
    "        \n",
    "        # Convert frequency into probability.\n",
    "        for keys,values in emission_prob.items():\n",
    "            total = 0\n",
    "            for value in values.values():\n",
    "                total = total + value\n",
    "            # Scan each symbol in symbol_set.\n",
    "            for symbol in symbol_set.values():\n",
    "                # Case-I: symbol is already existing\n",
    "                if symbol in values.keys():\n",
    "#                     emission_prob[keys][symbol] = round((emission_prob[keys][symbol]+1)/(total+M+1),1)\n",
    "                    emission_prob[keys][symbol] = (emission_prob[keys][symbol]+1)/(total+M+1)\n",
    "                # Case-II: symbol is not existing\n",
    "                else:\n",
    "#                     emission_prob.setdefault(keys,{})[symbol] = round(1/(total+M+1),1)\n",
    "                    emission_prob.setdefault(keys,{})[symbol] = 1/(total+M+1)\n",
    "            # Add special symbol \"UNK\".\n",
    "#             emission_prob.setdefault(keys,{})[M] = round(1/(total+M+1),1)\n",
    "            emission_prob.setdefault(keys,{})[M] = 1/(total+M+1)\n",
    "                                      \n",
    "    return M, symbol_set, emission_prob\n",
    "\n",
    "def parse_query(line):\n",
    "    '''\n",
    "    :param line: an address to be parsed\n",
    "    :return tokens: parsed tokens sequence\n",
    "    '''\n",
    "    pattern = re.compile(r\"[A-Za-z0-9.]+|[,&-/()]\")\n",
    "    tokens = pattern.findall(line)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(O, Q, PI, A, B):\n",
    "    '''\n",
    "    :param O: observations\n",
    "    :param Q: states\n",
    "    :param PI: state probability\n",
    "    :param A: transition probability\n",
    "    :param B: emission probability\n",
    "    :return path: the most possible state path\n",
    "    :return prob: the largest probability  \n",
    "    '''\n",
    "    # Step 0: Define two matrix -- delta, psi.\n",
    "    N = len(Q)\n",
    "    T = len(O)\n",
    "    # delta -- delta[t,i] -- 在时刻t，以状态i作为途径状态的最大的概率值是多少\n",
    "    # delta[t,i] -- k个最高的概率值 == > delta[t,i,k]\n",
    "    delta = np.zeros((T,N), float)     # highest probability of any path that ends at i\n",
    "    # psi[t,i] -- 在时刻t，上述delta最大值的时候返回的状态是什么\n",
    "    psi = np.zeros((T,N), int)         # argmax state\n",
    "        \n",
    "    # Step 1: Initialize local states when t=0.\n",
    "    delta[0, :] = PI * B[:,O[0]]\n",
    "    \n",
    "    # 对应课件里的初始化工作\n",
    "    for i in range(N):\n",
    "        delta[0,i] = PI[i]*B[i,O[0]]\n",
    "\n",
    "    # Step 2: Continue DP to compute local state in t = 1,3,...,T-1.\n",
    "    for t in range(1, T):\n",
    "        # Consider each state s2 (t) from previous state s1 (t-1)\n",
    "        # t时刻，在状态s2确定的条件下，\n",
    "        for s2 in range(N):\n",
    "            # 遍历一次所有的状态，这些状态s1被认为是在t-1时间的结果\n",
    "            for s1 in range(N):\n",
    "                # 更新的过程 -- 对应课件里面的递归公式\n",
    "                prob = delta[t-1, s1] * A[s1,s2] * B[s2,O[t]]\n",
    "                if prob > delta[t, s2]:\n",
    "                    delta[t, s2] = prob   # 记录最大概率值\n",
    "                    psi[t, s2] = s1       #记录最大概率对应的状态值\n",
    "    \n",
    "    # Step 3: Compute the max delta value at T, which is the probability of most possible state sequence.\n",
    "    # 直接计算最大的概率值作为返回信息\n",
    "    max_prob = np.max(delta[T-1,:])\n",
    "    \n",
    "    # Step 4: Compute the most possible state at T.\n",
    "    # 对应的状态值是哪个\n",
    "    state_last = np.argmax(delta[T-1,:])\n",
    "    \n",
    "    # Step 5: Backtracking for t = T-1, T-2, ..., 1.\n",
    "    path = np.zeros(T, int)         # initialize blank path\n",
    "    path[-1] = state_last           # path is from tail to head\n",
    "    \n",
    "    for t in range(T - 2, -1, -1):\n",
    "        # 在t+1时刻产生的最大的概率值对应的状态\n",
    "        path[t] = psi[[t + 1], path[t + 1]]\n",
    "    \n",
    "    return path, np.log(max_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_algorithm(State_File, Symbol_File, Query_File): # do not change the heading of the function\n",
    "    '''\n",
    "    :param State_File: state file\n",
    "    :param Symbol_File: symbol file\n",
    "    :param Query_File: query file\n",
    "    '''\n",
    "    \n",
    "    # Generate state information.\n",
    "    # N--有多少个状态\n",
    "    # state_set -- 状态集合 \n",
    "    # transition_prob -- 转移矩阵\n",
    "    # state_prob -- 初始状态概率值 π (暂时假定状态均匀分布)\n",
    "    N, state_set, transition_prob, state_prob = read_state(State_File)\n",
    "    \n",
    "    # Generate symbol information.    \n",
    "    # M -- 有多少个观测值\n",
    "    # symbol_set -- 观测值集合\n",
    "    # emission_prob -- 状态释放观测值的矩阵\n",
    "    M, symbol_set, emission_prob = read_symbol(Symbol_File, state_set)\n",
    "    \n",
    "    # Starting query.\n",
    "    with open(Query_File, 'r') as file:\n",
    "        while True:\n",
    "            # Parse each line.\n",
    "            line = file.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            query_seq = parse_query(line)      \n",
    "            \n",
    "            # Generate observations and initialized state probabiltiy.\n",
    "            O = [M for i in range(len(query_seq))]\n",
    "            for i in range(len(query_seq)):\n",
    "                if query_seq[i] in symbol_set.keys():\n",
    "                    O[i] = symbol_set[query_seq[i]]\n",
    "\n",
    "            Q = range(N)                # 观测序列\n",
    "            \n",
    "            # Convert dict into matrix -- A and B.\n",
    "            A = np.zeros((N,N))         # 转移矩阵\n",
    "            B = np.zeros((N, M+1))      # 状态释放观测值的概率矩阵\n",
    "            PI = [0 for i in range(N)]  # 初始化的状态分布(暂时假定均匀分布)\n",
    "\n",
    "            for i in range(N):\n",
    "                for j in range(N):\n",
    "                    A[i,j] = transition_prob[i][j]\n",
    "\n",
    "            for i in range(N):\n",
    "                for j in range(M+1):\n",
    "                    if i < N-2:\n",
    "                        B[i,j] = emission_prob[i][j]\n",
    "                    else:\n",
    "                        B[i,j] = 0.0\n",
    "                        \n",
    "            for i in range(N):\n",
    "                PI[i] = state_prob[i]  \n",
    "            \n",
    "#             PI = [1/3, 1/3, 1/3, 0.0, 0.0]\n",
    "#             PI = [11/36, 11/36, 11/36, 3/36, 0.0]\n",
    "            path, max_pro = viterbi(O, Q, PI, A, B)\n",
    "            \n",
    "            \n",
    "            # Join \"BEGIN\" and \"END\".\n",
    "            output = []\n",
    "            output.append(state_set['BEGIN'])\n",
    "            output.extend(path)\n",
    "            output.append(state_set['END'])\n",
    "            output.append(max_pro)\n",
    "            print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 0, 1, 2, 4, -8.185175305144405]\n",
      "[3, 2, 1, 2, 4, -7.738888202515985]\n"
     ]
    }
   ],
   "source": [
    "State_File ='./toy_example/State_File'\n",
    "Symbol_File='./toy_example/Symbol_File'\n",
    "Query_File ='./toy_example/Query_File'\n",
    "viterbi_result = viterbi_algorithm(State_File, Symbol_File, Query_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def file_reader(State_File, Symbol_File,q_3):\n",
    "    num_state = 0\n",
    "    state_dict = dict()\n",
    "    trans_dict = dict()\n",
    "    symbol_dict = dict()\n",
    "    emission_dict = dict()\n",
    "    trans_matix = np.matrix\n",
    "    emission_matrix = np.matrix\n",
    "    init_matrix = np.matrix\n",
    "    if q_3:\n",
    "        smooth = 0.0001\n",
    "    else:\n",
    "        smooth = 1\n",
    "    with open(State_File, 'r') as state_f:\n",
    "        num_state = int(state_f.readline().rstrip())\n",
    "        for i in range(num_state):\n",
    "            line = state_f.readline().rstrip()\n",
    "            state_dict[line] = i\n",
    "        while True:\n",
    "            line = state_f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line_ = line.rstrip().split(' ')\n",
    "            line_ = list(map(int, line_))\n",
    "            trans_dict.setdefault(line_[0], {})\n",
    "            trans_dict[line_[0]][line_[1]] = line_[2]\n",
    "\n",
    "        trans_matix = np.zeros((num_state,num_state),float)\n",
    "        for i in range(num_state):\n",
    "            if state_dict['END'] != i:\n",
    "                if i in trans_dict.keys():\n",
    "                    sum_v = sum(trans_dict[i].values())\n",
    "                else:\n",
    "                    sum_v = 0\n",
    "                for j in range(num_state):\n",
    "                    if j == state_dict['BEGIN']:\n",
    "                        continue\n",
    "                    if j in trans_dict[i].keys() and i in trans_dict.keys():\n",
    "                        trans_matix[i,j] = (smooth + trans_dict[i][j])/(sum_v+(smooth*num_state)-1)\n",
    "                    else:\n",
    "                        trans_matix[i,j] = smooth/(sum_v+(smooth*num_state)-1)\n",
    "                if i == state_dict['BEGIN']:\n",
    "                    init_matrix=trans_matix[i,:]\n",
    "\n",
    "    with open(Symbol_File, 'r') as symbol_f:\n",
    "        num_symbol = int(symbol_f.readline().rstrip())\n",
    "        for i in range(num_symbol):\n",
    "            line = symbol_f.readline().rstrip()\n",
    "            symbol_dict[line] = i\n",
    "        while True:\n",
    "            line = symbol_f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line_ = line.rstrip().split(' ')\n",
    "            line_ = list(map(int, line_))\n",
    "            emission_dict.setdefault(line_[0], {})\n",
    "            emission_dict[line_[0]][line_[1]] = line_[2]\n",
    "\n",
    "        emission_matrix = np.zeros((num_state,num_symbol+1))\n",
    "        for i in range(num_state):\n",
    "            if state_dict['BEGIN'] != i and state_dict['END'] != i:\n",
    "                if i in emission_dict.keys():\n",
    "                    sum_v = sum(emission_dict[i].values())\n",
    "                else:\n",
    "                    sum_v = 0\n",
    "                for j in range(num_symbol+1):\n",
    "                    if j in emission_dict[i].keys() and i in emission_dict.keys():\n",
    "                        emission_matrix[i,j] = (smooth+emission_dict[i][j])/(sum_v+smooth*num_symbol+1)\n",
    "                    else:\n",
    "                        emission_matrix[i,j] = smooth/(sum_v+smooth*num_symbol+1)\n",
    "    # print(emission_matrix)\n",
    "    return num_state,num_symbol,state_dict,symbol_dict,trans_matix,emission_matrix,init_matrix\n",
    "\n",
    "\n",
    "def viterbi_alg(num_state,num_symbol,state_dict,symbol_dict,trans_matix,emission_matrix,init_matrix,query,k):\n",
    "    # DP\n",
    "    dpmatrix = []\n",
    "    for i in range(num_state):\n",
    "        dpmatrix.append([])\n",
    "        for j in range(len(query)+2):\n",
    "            # dpmatrix[i].append([(0.0,[])]*k)\n",
    "            dpmatrix[i].append([])\n",
    "            for m in range(k):\n",
    "                dpmatrix[i][j].append([])\n",
    "                dpmatrix[i][j][m].append(0.0)\n",
    "                dpmatrix[i][j][m].append([])\n",
    "    # init\n",
    "    print(dpmatrix)\n",
    "    dpmatrix[state_dict['BEGIN']][0][0] = [1,[]]\n",
    "    for i in range(num_state):\n",
    "        # print(dpmatrix[i][1][0][0])\n",
    "        if query[0] in symbol_dict.keys():\n",
    "            dpmatrix[i][1][0][0] = init_matrix[i] * emission_matrix[i, symbol_dict[query[0]]]\n",
    "        else:\n",
    "            dpmatrix[i][1][0][0] = init_matrix[i] * emission_matrix[i, symbol_dict['UNK']]\n",
    "        dpmatrix[i][1][0][1].append(state_dict['BEGIN'])\n",
    "    print(dpmatrix)\n",
    "\n",
    "    for j in range(2,len(query)+1):\n",
    "        for i in range(num_state):\n",
    "            tmp = []\n",
    "            for m in range(num_state):\n",
    "                for y in range(k):\n",
    "                    if query[j-1] in symbol_dict.keys():\n",
    "                        tmp.append( (dpmatrix[m][j - 1][y][0] * trans_matix[m, i] * emission_matrix[i, symbol_dict[query[j-1]]],dpmatrix[m][j - 1][y][1]+[m]) )\n",
    "                    else:\n",
    "                        tmp.append((dpmatrix[m][j - 1][y][0] * trans_matix[m, i] * emission_matrix[i, symbol_dict['UNK']], dpmatrix[m][j - 1][y][1]+[m]))\n",
    "            tmp = sorted(tmp, key=lambda x: x[0], reverse=True)\n",
    "            #print('tmp',tmp)\n",
    "            for n in range(k):\n",
    "                #print(tmp[n])\n",
    "                dpmatrix[i][j][n][0] = tmp[n][0]\n",
    "                dpmatrix[i][j][n][1].extend(tmp[n][1])\n",
    "    print(trans_matix)\n",
    "    print(trans_matix[:,state_dict['END']])\n",
    "\n",
    "    for i in range(num_state):\n",
    "        for j in range(k):\n",
    "            end_matrix = trans_matix[:,state_dict['END']]\n",
    "            dpmatrix[i][len(query)+1][j][0] = end_matrix[i] * dpmatrix[i][len(query)][j][0]\n",
    "            dpmatrix[i][len(query) + 1][j][1].extend(dpmatrix[i][len(query)][j][1]+[i])\n",
    "\n",
    "#     for row in emission_matrix:\n",
    "#         print(row)\n",
    "#         print()\n",
    "\n",
    "    r = []\n",
    "\n",
    "\n",
    "    for i in range(num_state):\n",
    "        r.extend(dpmatrix[i][len(query)+1])\n",
    "    r = sorted(r,key=lambda x: x[0], reverse=True)\n",
    "    # print(r)\n",
    "    result = []\n",
    "    result_l = []\n",
    "    end = state_dict['END']\n",
    "    for i in range(k):\n",
    "        result = r[i][1] +[end]+[np.log(r[i][0])]\n",
    "        result_l.append(result)\n",
    "    # print(result_l)\n",
    "    return result_l\n",
    "\n",
    "\n",
    "# Question 1\n",
    "def viterbi_algorithm(State_File, Symbol_File, Query_File): # do not change the heading of the function\n",
    "    num_state,num_symbol,state_dict,symbol_dict,trans_matix,emission_matrix,init_matrix = file_reader(State_File, Symbol_File,False)\n",
    "    pattern = r\"[0-9A-Za-z.]+|[,&-/()]\"\n",
    "    result = []\n",
    "    with open(Query_File, 'r') as query_f:\n",
    "        while True:\n",
    "            line = query_f.readline().rstrip()\n",
    "            if not line:\n",
    "                break\n",
    "            query = re.compile(pattern).findall(line)\n",
    "            # print('query', query)\n",
    "            symbol_dict[\"UNK\"] = num_symbol\n",
    "\n",
    "            result.extend(viterbi_alg(num_state,num_symbol,state_dict,symbol_dict,trans_matix,emission_matrix,init_matrix,query,1))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]]], [[[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]]], [[[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]]], [[[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]]], [[[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]]]]\n",
      "[[[[0.0, []]], [[0.11428571428571428, [3]]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]]], [[[0.0, []]], [[0.05714285714285714, [3]]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]]], [[[0.0, []]], [[0.05714285714285714, [3]]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]]], [[[1, []]], [[0.0, [3]]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]]], [[[0.0, []]], [[0.0, [3]]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]]]]\n",
      "[[0.46666667 0.2        0.2        0.         0.13333333]\n",
      " [0.13333333 0.26666667 0.46666667 0.         0.13333333]\n",
      " [0.26666667 0.46666667 0.13333333 0.         0.13333333]\n",
      " [0.28571429 0.28571429 0.28571429 0.         0.14285714]\n",
      " [0.         0.         0.         0.         0.        ]]\n",
      "[0.13333333 0.13333333 0.13333333 0.14285714 0.        ]\n",
      "[[[[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]]], [[[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]]], [[[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]]], [[[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]]], [[[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]], [[0.0, []]]]]\n",
      "[[[[0.0, []]], [[0.11428571428571428, [3]]], [[0.0, []]], [[0.0, []]], [[0.0, []]]], [[[0.0, []]], [[0.05714285714285714, [3]]], [[0.0, []]], [[0.0, []]], [[0.0, []]]], [[[0.0, []]], [[0.05714285714285714, [3]]], [[0.0, []]], [[0.0, []]], [[0.0, []]]], [[[1, []]], [[0.0, [3]]], [[0.0, []]], [[0.0, []]], [[0.0, []]]], [[[0.0, []]], [[0.0, [3]]], [[0.0, []]], [[0.0, []]], [[0.0, []]]]]\n",
      "[[0.46666667 0.2        0.2        0.         0.13333333]\n",
      " [0.13333333 0.26666667 0.46666667 0.         0.13333333]\n",
      " [0.26666667 0.46666667 0.13333333 0.         0.13333333]\n",
      " [0.28571429 0.28571429 0.28571429 0.         0.14285714]\n",
      " [0.         0.         0.         0.         0.        ]]\n",
      "[0.13333333 0.13333333 0.13333333 0.14285714 0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[3, 0, 0, 1, 2, 4, -9.843403381747937], [3, 2, 1, 2, 4, -9.397116279119517]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "State_File ='./toy_example/State_File'\n",
    "Symbol_File='./toy_example/Symbol_File'\n",
    "Query_File ='./toy_example/Query_File'\n",
    "viterbi_algorithm(State_File, Symbol_File, Query_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
