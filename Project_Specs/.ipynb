{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "# from __future__ import division\n",
    "\n",
    "def read_state(State_File):\n",
    "    '''\n",
    "    :param State_File: file includes state set and state transition matrix\n",
    "    :return N: number of states\n",
    "    :return state_set: a dict contains all states' ID and name\n",
    "    :return transition_prob: a dict contains transition probability \n",
    "    :return state_prob: a dict contains states and their probability\n",
    "    '''\n",
    "    with open(State_File, 'r') as file:\n",
    "        N = int(file.readline().strip('\\n'))     # read the first line to get N value\n",
    "        state_set = dict()                       # store the set of state\n",
    "        transition_prob = dict()                 # store transition probability  \n",
    "        state_prob = dict()                      # store state initialising probability\n",
    "        ID = 0                                   # ID of states\n",
    "        cnt = 0                                  # number of transitions\n",
    "        \n",
    "        # Scan descriptive name of the states.\n",
    "        while ID < N:\n",
    "            state = file.readline().strip('\\n').rstrip()  # one state in each line\n",
    "            state_set[state] = ID\n",
    "            ID = ID + 1\n",
    "        \n",
    "        # Scan the frequency of transitions.\n",
    "        while True:\n",
    "            line = file.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            items = line.split(' ')\n",
    "            # Add new probability with key + value.\n",
    "            transition_prob.setdefault(int(items[0]),{})[int(items[1])] = int(items[2])\n",
    "            cnt = cnt + 1\n",
    "        \n",
    "        # Convert frequency into probability.\n",
    "        for keys,values in transition_prob.items():\n",
    "            total = 0\n",
    "            for value in values.values():\n",
    "                total = total + value\n",
    "            # Scan each state in state_set.\n",
    "            for state in state_set.values():\n",
    "                # Case-I: state is already existing\n",
    "                if state in values.keys():\n",
    "#                     transition_prob[keys][state] = round((transition_prob[keys][state]+1)/(total+N-1),1)\n",
    "                    transition_prob[keys][state] = (transition_prob[keys][state]+1)/(total+N-1)\n",
    "                # Case-II: state is not existing\n",
    "                else:\n",
    "                    if state == state_set['BEGIN']:\n",
    "                        transition_prob.setdefault(keys,{})[state] = 0.0\n",
    "                    else:\n",
    "#                         transition_prob.setdefault(keys,{})[state] = round(1/(total+N-1),1)\n",
    "                        transition_prob.setdefault(keys,{})[state] = 1/(total+N-1)\n",
    "            \n",
    "        # Initialize state probability and Add \"END\" state with no outing states.\n",
    "        for state in state_set.values():\n",
    "            transition_prob.setdefault(state_set['END'],{})[state] = 0.0\n",
    "#             state_prob[state] = round(1/N,1)\n",
    "            state_prob[state] = 1/N\n",
    "            \n",
    "    return N, state_set, transition_prob, state_prob\n",
    "\n",
    "def read_symbol(Symbol_File, state_set):\n",
    "    '''\n",
    "    :param Symbol_File: file includes symbol set and emission probability\n",
    "    :param state_set: a set of state\n",
    "    :return M: number of symbol\n",
    "    :return symbol_set: a dict contains all symbols' ID and name\n",
    "    :return emission_prob: a dict contains emission probability \n",
    "    '''\n",
    "    with open(Symbol_File, 'r') as file:\n",
    "        M = int(file.readline().strip('\\n'))     # read the first line to get M value\n",
    "        symbol_set = dict()                      # store the set of symbol\n",
    "        emission_prob = dict()                   # store emission probability        \n",
    "        ID = 0                                   # ID of symbols\n",
    "        \n",
    "        # Scan descriptive name of the symbols.\n",
    "        while ID < M:\n",
    "            symbol = file.readline().strip('\\n').rstrip()  # one symbol in each line\n",
    "#             symbol_set[ID] = symbol\n",
    "            symbol_set[symbol] = ID\n",
    "            ID = ID + 1\n",
    "        \n",
    "        # Scan the frequency of emissions.\n",
    "        while True:\n",
    "            line = file.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            items = line.split(' ')\n",
    "            # Add new probability with key + value.\n",
    "            emission_prob.setdefault(int(items[0]),{})[int(items[1])] = int(items[2])\n",
    "        \n",
    "        # Convert frequency into probability.\n",
    "        for keys,values in emission_prob.items():\n",
    "            total = 0\n",
    "            for value in values.values():\n",
    "                total = total + value\n",
    "            # Scan each symbol in symbol_set.\n",
    "            for symbol in symbol_set.values():\n",
    "                # Case-I: symbol is already existing\n",
    "                if symbol in values.keys():\n",
    "#                     emission_prob[keys][symbol] = round((emission_prob[keys][symbol]+1)/(total+M+1),1)\n",
    "                    emission_prob[keys][symbol] = (emission_prob[keys][symbol]+1)/(total+M+1)\n",
    "                # Case-II: symbol is not existing\n",
    "                else:\n",
    "#                     emission_prob.setdefault(keys,{})[symbol] = round(1/(total+M+1),1)\n",
    "                    emission_prob.setdefault(keys,{})[symbol] = 1/(total+M+1)\n",
    "            # Add special symbol \"UNK\".\n",
    "#             emission_prob.setdefault(keys,{})[M] = round(1/(total+M+1),1)\n",
    "            emission_prob.setdefault(keys,{})[M] = 1/(total+M+1)\n",
    "                                      \n",
    "    return M, symbol_set, emission_prob\n",
    "\n",
    "def parse_query(line):\n",
    "    '''\n",
    "    :param line: an address to be parsed\n",
    "    :return tokens: parsed tokens sequence\n",
    "    '''\n",
    "    pattern = re.compile(r\"[A-Za-z0-9.]+|[,&-/()]\")\n",
    "    tokens = pattern.findall(line)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(O, Q, PI, A, B):\n",
    "    '''\n",
    "    :param O: observations\n",
    "    :param Q: states\n",
    "    :param PI: state probability\n",
    "    :param A: transition probability\n",
    "    :param B: emission probability\n",
    "    :return path: the most possible state path\n",
    "    :return prob: the largest probability  \n",
    "    '''\n",
    "    # Step 0: Define two matrix -- delta, psi.\n",
    "    N = len(Q)\n",
    "    T = len(O)\n",
    "    # delta -- delta[t,i] -- 在时刻t，以状态i作为途径状态的最大的概率值是多少\n",
    "    # delta[t,i] -- k个最高的概率值 == > delta[t,i,k]\n",
    "    delta = np.zeros((T,N), float)     # highest probability of any path that ends at i\n",
    "    # psi[t,i] -- 在时刻t，上述delta最大值的时候返回的状态是什么\n",
    "    psi = np.zeros((T,N), int)         # argmax state\n",
    "        \n",
    "    # Step 1: Initialize local states when t=0.\n",
    "    delta[0, :] = PI * B[:,O[0]]\n",
    "    \n",
    "    # 对应课件里的初始化工作\n",
    "    for i in range(N):\n",
    "        delta[0,i] = PI[i]*B[i,O[0]]\n",
    "\n",
    "    # Step 2: Continue DP to compute local state in t = 1,3,...,T-1.\n",
    "    for t in range(1, T):\n",
    "        # Consider each state s2 (t) from previous state s1 (t-1)\n",
    "        # t时刻，在状态s2确定的条件下，\n",
    "        for s2 in range(N):\n",
    "            # 遍历一次所有的状态，这些状态s1被认为是在t-1时间的结果\n",
    "            for s1 in range(N):\n",
    "                # 更新的过程 -- 对应课件里面的递归公式\n",
    "                prob = delta[t-1, s1] * A[s1,s2] * B[s2,O[t]]\n",
    "                if prob > delta[t, s2]:\n",
    "                    delta[t, s2] = prob   # 记录最大概率值\n",
    "                    psi[t, s2] = s1       #记录最大概率对应的状态值\n",
    "    \n",
    "    # Step 3: Compute the max delta value at T, which is the probability of most possible state sequence.\n",
    "    # 直接计算最大的概率值作为返回信息\n",
    "    max_prob = np.max(delta[T-1,:])\n",
    "    \n",
    "    # Step 4: Compute the most possible state at T.\n",
    "    # 对应的状态值是哪个\n",
    "    state_last = np.argmax(delta[T-1,:])\n",
    "    \n",
    "    # Step 5: Backtracking for t = T-1, T-2, ..., 1.\n",
    "    path = np.zeros(T, int)         # initialize blank path\n",
    "    path[-1] = state_last           # path is from tail to head\n",
    "    \n",
    "    for t in range(T - 2, -1, -1):\n",
    "        # 在t+1时刻产生的最大的概率值对应的状态\n",
    "        path[t] = psi[[t + 1], path[t + 1]]\n",
    "    \n",
    "    return path, np.log(max_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_algorithm(State_File, Symbol_File, Query_File): # do not change the heading of the function\n",
    "    '''\n",
    "    :param State_File: state file\n",
    "    :param Symbol_File: symbol file\n",
    "    :param Query_File: query file\n",
    "    '''\n",
    "    \n",
    "    # Generate state information.\n",
    "    # N--有多少个状态\n",
    "    # state_set -- 状态集合 \n",
    "    # transition_prob -- 转移矩阵\n",
    "    # state_prob -- 初始状态概率值 π (暂时假定状态均匀分布)\n",
    "    N, state_set, transition_prob, state_prob = read_state(State_File)\n",
    "    \n",
    "    # Generate symbol information.    \n",
    "    # M -- 有多少个观测值\n",
    "    # symbol_set -- 观测值集合\n",
    "    # emission_prob -- 状态释放观测值的矩阵\n",
    "    M, symbol_set, emission_prob = read_symbol(Symbol_File, state_set)\n",
    "    \n",
    "    # Starting query.\n",
    "    with open(Query_File, 'r') as file:\n",
    "        while True:\n",
    "            # Parse each line.\n",
    "            line = file.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            query_seq = parse_query(line)      \n",
    "            \n",
    "            # Generate observations and initialized state probabiltiy.\n",
    "            O = [M for i in range(len(query_seq))]\n",
    "            for i in range(len(query_seq)):\n",
    "                if query_seq[i] in symbol_set.keys():\n",
    "                    O[i] = symbol_set[query_seq[i]]\n",
    "\n",
    "            Q = range(N)                # 观测序列\n",
    "            \n",
    "            # Convert dict into matrix -- A and B.\n",
    "            A = np.zeros((N,N))         # 转移矩阵\n",
    "            B = np.zeros((N, M+1))      # 状态释放观测值的概率矩阵\n",
    "            PI = [0 for i in range(N)]  # 初始化的状态分布(暂时假定均匀分布)\n",
    "\n",
    "            for i in range(N):\n",
    "                for j in range(N):\n",
    "                    A[i,j] = transition_prob[i][j]\n",
    "\n",
    "            for i in range(N):\n",
    "                for j in range(M+1):\n",
    "                    if i < N-2:\n",
    "                        B[i,j] = emission_prob[i][j]\n",
    "                    else:\n",
    "                        B[i,j] = 0.0\n",
    "                        \n",
    "            for i in range(N):\n",
    "                PI[i] = state_prob[i]  \n",
    "            \n",
    "#             PI = [1/3, 1/3, 1/3, 0.0, 0.0]\n",
    "#             PI = [11/36, 11/36, 11/36, 3/36, 0.0]\n",
    "            path, max_pro = viterbi(O, Q, PI, A, B)\n",
    "            \n",
    "            \n",
    "            # Join \"BEGIN\" and \"END\".\n",
    "            output = []\n",
    "            output.append(state_set['BEGIN'])\n",
    "            output.extend(path)\n",
    "            output.append(state_set['END'])\n",
    "            output.append(max_pro)\n",
    "            print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 0, 1, 2, 4, -8.185175305144405]\n",
      "[3, 2, 1, 2, 4, -7.738888202515985]\n"
     ]
    }
   ],
   "source": [
    "State_File ='./toy_example/State_File'\n",
    "Symbol_File='./toy_example/Symbol_File'\n",
    "Query_File ='./toy_example/Query_File'\n",
    "viterbi_result = viterbi_algorithm(State_File, Symbol_File, Query_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
